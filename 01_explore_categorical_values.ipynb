{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listings data-set contains listings from Seattle with descriptive and rating information about host and property.<br>\n",
    "There are also transactional information, like the price, fees or guest-requirements.<br>\n",
    "By focusing on the listings data set one keeps the option open to later add new feature from the other two data-sets if necessary.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The Business Objective\n",
    "\n",
    "The Airbnb platform is a service to bring two parties together, the host and guest.<br>\n",
    "*For further analysis let us assume the perspective of a host.*<br>\n",
    "\n",
    "**What is the hosts objective?**\n",
    "\n",
    "A host usually already has a property and does not need to acquire one to rent it out.<br>\n",
    "The host wants to make extra money by renting the property out to guests.<br>\n",
    "Obviously a host wants to maximize the income from a property. One way to achieve that is to adjust the price.<br>\n",
    "But how far can one go reasonably without getting unrealistic and drive away potential guests?<br>\n",
    "\n",
    "**The questions we want to answer based on the given data are:**\n",
    "1. Which parameters influence a listings price?\n",
    "1. What parameter can the host use to improve price and value?\n",
    "1. Can we make a good price estimation for a new offer to assist the (new) host?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ExploreData import sort_mean, value_counter, index_by_key\n",
    "from TransformData import \\\n",
    "    price_transform, rate_transform, split_column_values, date_transform\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "df_listings = pd.read_csv('./data/listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Preparing the Data for Further Analysis\n",
    "\n",
    "Before analyzing the data some minimal cleaning needs to be done.<br>\n",
    "\n",
    "1. We learned already, that some columns can be neglected\n",
    "2. Some very important columns for our questions have the wrong data type.\n",
    "Since our questions are phrased openly we might want to work with many columns in the data set.\n",
    "Thus a close look at all categorical columns, which might be of interest, should be taken.\n",
    "\n",
    "### 1. Drop Columns\n",
    "\n",
    "It hast already been established in notebook number 00, that some columns can be dropped since they carry no information for the questions at hand or no information at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overview over the columns\n",
    "list_column_values = value_counter(df_listings)\n",
    "\n",
    "# Identify columns with constant values\n",
    "list_const_drop = list_column_values.loc[\n",
    "    list_column_values['val_count']==1\n",
    "    ].index\n",
    "\n",
    "# Identify columns with no values\n",
    "list_nan_drop = list_column_values.loc[\n",
    "    list_column_values['nan_pcnt']>=90\n",
    "    ].index\n",
    "\n",
    "# Identify url columns\n",
    "list_url_drop= df_listings.columns[\n",
    "    df_listings.columns.to_series().str.contains('url',case=False)]\n",
    "\n",
    "# Additional colums to drop\n",
    "list_else_drop = df_listings[[\n",
    "    'city', 'state', 'smart_location',\n",
    "    'host_name', 'host_location',\n",
    "    'neighbourhood', 'neighbourhood_cleansed'\n",
    "    ]].columns\n",
    "\n",
    "# Combine the lists\n",
    "drop_columns_list = list_const_drop.append(\n",
    "    list_nan_drop).append(\n",
    "    list_url_drop).append(\n",
    "    list_else_drop)\n",
    "# Drop the columns\n",
    "listings_drop_col = df_listings.drop(columns=drop_columns_list)\n",
    "\n",
    "# Check what has been droped\n",
    "df_listings[drop_columns_list].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Object-Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate object column names\n",
    "cat_listings = listings_drop_col.select_dtypes(include=['object'])\n",
    "\n",
    "# Create a df with column information\n",
    "cat_column_values = value_counter(cat_listings)\n",
    "\n",
    "# How many categorical values are there?\n",
    "cat_column_values.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many object columns. Not all of them are of use for the questions at hand.<br>\n",
    "So we look at them one by one.\n",
    "\n",
    "**Starting with columns that have many different values**<br>\n",
    "Many of these are text and have more than 80% unique values.<br>\n",
    "But there are also the *amenities* - which are basically lists of values per column entry. They can be extracted into a set of amenity-columns.<br>\n",
    "One can also transform the *price* to numeric after dropping the $-sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find categorical columns with more than 200 unique values\n",
    "cat_column_values.loc[cat_column_values['val_count']>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "listings_drop_col[cat_column_values.loc[cat_column_values['val_count']>200].index].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amenities\n",
    "The column has many unique values. But each entry is a list and the set of unique list-entries is not so big.<br>\n",
    "\n",
    "**Create a column for each unique amenity with values 0 and 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: Identify all possible values:\n",
    "# Create an auxilliary list to carry all values from splitted entries\n",
    "all_splitted = []\n",
    "# Split every entry into a list of amenities and append the resutl to all_splitted\n",
    "for i in listings_drop_col.index:\n",
    "    entry_split = listings_drop_col['amenities'][i].replace('{', '').replace('}', '').replace('\"', '').split(sep=\",\")\n",
    "    #listings_drop_col['amenities_split'][i] = entry_split\n",
    "    all_splitted = all_splitted+entry_split\n",
    "\n",
    "# Create all_entries by removing dublicates from all_splitted\n",
    "all_entries = list(set(all_splitted))\n",
    "all_entries.remove('')\n",
    "\n",
    "# Second: Use the split_column_values function\n",
    "# to create a new column for every value\n",
    "split_column_values(\n",
    "    listings_drop_col,  # data-frame\n",
    "    'amenities',  # column name\n",
    "    all_entries,  # values in a list\n",
    "    'amenities_'  # prefix for new columns\n",
    "    )\n",
    "\n",
    "# Drop the original column 'amenities'\n",
    "listings_drop_col.drop(columns=['amenities'], inplace= True)\n",
    "\n",
    "# Check the result:\n",
    "listings_drop_col[index_by_key(listings_drop_col, ['amenities'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Columns\n",
    "\n",
    "There are three dates in the above extract.\n",
    "* first_review\n",
    "* last_review\n",
    "* host_since\n",
    "\n",
    "At this point it is not clear weather they are all needed.<br>\n",
    "But it is no beg step to transform them into a date-type.<br>\n",
    "The function date_transform() also creates separate columns for day, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all dates into three columns\n",
    "date_transform(listings_drop_col, 'host_since', 'host_since_')\n",
    "date_transform(listings_drop_col, 'first_review', 'first_review_')\n",
    "date_transform(listings_drop_col, 'last_review', 'last_review_')\n",
    "# Drop original columns\n",
    "listings_drop_col = listings_drop_col.drop(\n",
    "    columns=['host_since','first_review','last_review'],\n",
    "    axis=1\n",
    "    )\n",
    "# Check the result:\n",
    "listings_drop_col[['host_since_year']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with more than 200 unique values also contain the *price* column. But there were more columns with currency values.<br>\n",
    "We check the remaining columns first and transform all currency-values at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overview over the columns values\n",
    "cat_column_values.loc[cat_column_values['val_count']<=200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the selected columns\n",
    "listings_drop_col[cat_column_values.loc[cat_column_values['val_count']<=200].index].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currency Columns\n",
    "\n",
    "There are six columns containing $-values. To transform them into a number one can use the *price_transform* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify currancy columns\n",
    "search_values = ['price', 'fee', 'deposit', 'extra']\n",
    "price_column_names  = index_by_key(listings_drop_col, search_values)\n",
    "# Check before transformation\n",
    "listings_drop_col[price_column_names].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a string type: convert to float\n",
    "for col in price_column_names :\n",
    "    listings_drop_col[col] = price_transform(listings_drop_col[col])\n",
    "# Check after transformation\n",
    "listings_drop_col[price_column_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rates\n",
    "\n",
    "Columns containing a rate can be dealt with just like currencies, just with the *rate_transform* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns\n",
    "search_values_rate = ['rate']\n",
    "rate_column_names  = index_by_key(listings_drop_col, search_values_rate)\n",
    "\n",
    "listings_drop_col[rate_column_names].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to float and check the result:\n",
    "for col in rate_column_names :\n",
    "    listings_drop_col[col] = rate_transform(listings_drop_col[col])\n",
    "\n",
    "listings_drop_col[rate_column_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Object-Columns\n",
    "\n",
    "Many columns contain only boolean information stored in strings: 't' and 'f'. These get mapped to 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify binary object columns\n",
    "binary_cols = cat_column_values.loc[cat_column_values['val_count']==2 ].index\n",
    "\n",
    "listings_drop_col[binary_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a value map:\n",
    "binary_map = {'t': 1, 'f': 0}\n",
    "\n",
    "# Map binary object-columns to 0 and 1:\n",
    "for col in binary_cols:\n",
    "    if listings_drop_col[col].dtype == 'object':\n",
    "        listings_drop_col[col] = listings_drop_col[col].map(binary_map)\n",
    "\n",
    "listings_drop_col[binary_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal Object-Columns\n",
    "\n",
    "Two columns, host_response_time and cancellation_policy, have very few values that can be sorted in some way.<br>\n",
    "We sort them and replace strings with increasing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_drop_col[['cancellation_policy', 'host_response_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for cancellation_policy\n",
    "listings_drop_col['host_response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for cancellation_policy\n",
    "listings_drop_col['host_response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create value maps for both columns\n",
    "policy_map = {'strict':2, 'moderate':1, 'flexible':0}\n",
    "response_map = {'a few days or more':3, 'within a day':2, 'within a few hours':1, 'within an hour':0}\n",
    "\n",
    "# Map both columns to new values\n",
    "listings_drop_col['host_response_time'] = listings_drop_col['host_response_time'].map(response_map)\n",
    "listings_drop_col['cancellation_policy'] = listings_drop_col['cancellation_policy'].map(policy_map)\n",
    "\n",
    "# Check\n",
    "listings_drop_col[['cancellation_policy', 'host_response_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the host columns look like?\n",
    "search_values_host = ['host', 'type']\n",
    "host_column_names  = listings_drop_col.columns[\n",
    "    listings_drop_col.columns.to_series().str.contains('|'.join(search_values_host),case=False)]\n",
    "\n",
    "listings_drop_col[host_column_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### host_verifications\n",
    "\n",
    "There is one column left the should be transformed at this point.<br>\n",
    "host_verifications looks similar to amenities, with only small differences.\n",
    "\n",
    "**Create a column for each unique verification method with values 0 and 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_drop_col['host_verifications'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split entries into single values and create one column per value\n",
    "\n",
    "# Find all values\n",
    "all_splitted = []\n",
    "for i in listings_drop_col.index:\n",
    "        entry_split = listings_drop_col['host_verifications'].loc[i].replace(\n",
    "                '[', '').replace(']', '').replace(\"'\", \"\").split(sep=\", \")\n",
    "        all_splitted = all_splitted+entry_split\n",
    "# Remove dublicates\n",
    "all_entries = list(set(all_splitted))\n",
    "all_entries.remove('')\n",
    "all_entries.remove('None')\n",
    "# Create new columns and add a prefix to new column names\n",
    "split_column_values(\n",
    "        listings_drop_col, \n",
    "        'host_verifications', \n",
    "        all_entries, \n",
    "        '_host_verifications'\n",
    "        )\n",
    "# Drop the original column \n",
    "listings_drop_col = listings_drop_col.drop(columns='host_verifications', axis=1)\n",
    "\n",
    "# Check the result\n",
    "listings_drop_col[index_by_key(listings_drop_col, ['host_verifications'])].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "For now all rellevant columns are transoformed into a type and shape that makes them accessable for further analysis.<br>\n",
    "The final look at the object columns confirm: They have been reduced in numbers significantly.<br>\n",
    "The data-frames dimensions on the other hand shows an increased number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data-frames dimensions\n",
    "listings_drop_col.shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many object columns are left and are they relevant to the problem?\n",
    "\n",
    "# Isolate object column names:\n",
    "cat_listings = listings_drop_col.select_dtypes(include=['object'])\n",
    "# Create a df with column information: \n",
    "cat_column_values = value_counter(cat_listings)\n",
    "\n",
    "cat_column_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
